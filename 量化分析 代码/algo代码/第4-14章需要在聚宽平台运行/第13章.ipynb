{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: tensorflow\r\n",
      "Version: 1.12.2\r\n",
      "Summary: TensorFlow is an open source machine learning framework for everyone.\r\n",
      "Home-page: https://www.tensorflow.org/\r\n",
      "Author: Google Inc.\r\n",
      "Author-email: opensource@google.com\r\n",
      "License: Apache 2.0\r\n",
      "Location: /opt/conda/lib/python3.6/site-packages\r\n",
      "Requires: tensorboard, grpcio, numpy, wheel, absl-py, astor, keras-preprocessing, six, termcolor, protobuf, gast, keras-applications\r\n",
      "Required-by: \r\n"
     ]
    }
   ],
   "source": [
    "#先来看看平台是否提供了tensorflw\n",
    "!pip show tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Keras\r\n",
      "Version: 2.2.4\r\n",
      "Summary: Deep Learning for humans\r\n",
      "Home-page: https://github.com/keras-team/keras\r\n",
      "Author: Francois Chollet\r\n",
      "Author-email: francois.chollet@gmail.com\r\n",
      "License: MIT\r\n",
      "Location: /opt/conda/lib/python3.6/site-packages\r\n",
      "Requires: keras-preprocessing, six, keras-applications, numpy, h5py, pyyaml, scipy\r\n",
      "Required-by: \r\n"
     ]
    }
   ],
   "source": [
    "#如果有keras就更好了\n",
    "!pip show keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#导入keras，看看在用什么做后端\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#导入要用到的库\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#这次我们使用keras内置的tokenizer来处理文本数据\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "#导入一个用来填充序列的工具\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "#导入全连接层和Dropout层\n",
    "from keras.layers import Dense, Dropout\n",
    "#导入model类中的Sequential\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9214 entries, 0 to 9213\n",
      "Data columns (total 2 columns):\n",
      "text        9214 non-null object\n",
      "polarity    9214 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 144.0+ KB\n"
     ]
    }
   ],
   "source": [
    "#这个单元格中的内容就是在第12章中用过的\n",
    "#载入数据并添加极性标签\n",
    "#并合成一个DataFrame的代码\n",
    "#本章中就不逐行注释了\n",
    "pos_corpus = []\n",
    "with open('positive.txt','r') as f:\n",
    "    for sent in f:\n",
    "        pos_corpus.append(sent.replace('\\n', ''))\n",
    "neg_corpus = []\n",
    "with open('negtive.txt', 'r') as f:\n",
    "    for sent in f:\n",
    "        neg_corpus.append(sent.replace('\\n', ''))\n",
    "pos_df = pd.DataFrame(pos_corpus, columns=['text'])\n",
    "pos_df['polarity'] = 1\n",
    "neg_df = pd.DataFrame(neg_corpus, columns=['text'])\n",
    "neg_df['polarity'] = 0\n",
    "df = pd.concat([pos_df, neg_df]).reset_index(drop = True)\n",
    "#检查一下DataFrame的信息\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#首先还是将文本作为样本特征\n",
    "X = df['text']\n",
    "#极性标签作为目标\n",
    "y = df['polarity'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'买入 长期 持有 沃森 生物 19条 简短 想法'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15644"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#这里使用keras中的tokenizer来进行向量的转化\n",
    "#filter参数可以就使用下面这行代码中的\n",
    "#这样一般的标点符号和特殊字符就会被过滤出去\n",
    "tokenizer = Tokenizer(filters = '!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "                     lower = True, split=\" \")\n",
    "#用tokenizer拟合文本数据\n",
    "tokenizer.fit_on_texts(X)\n",
    "#文本特征存储在word_index中\n",
    "vocab = tokenizer.word_index\n",
    "#可以检查一下特征的数量\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'不': 1,\n",
       " '今天': 2,\n",
       " '大': 3,\n",
       " '涨停': 4,\n",
       " '明天': 5,\n",
       " '跌': 6,\n",
       " '大盘': 7,\n",
       " '都': 8,\n",
       " '涨': 9,\n",
       " '股': 10}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#如果大家好奇的话，可以查看一下前几个特征\n",
    "slice_dict = {k: vocab[k] for k in list(vocab.keys())[0:10]}\n",
    "slice_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#这里导入scikit-learn的数据集拆分工具\n",
    "from sklearn.model_selection import train_test_split\n",
    "#将数据集拆分为训练集和验证集\n",
    "X_train, X_test, y_train, y_test =\\\n",
    "train_test_split(X, y, random_state = 30)\n",
    "#使用texts_to_sequences就可以把文本转化为序列\n",
    "#这个序列可以看成是数组\n",
    "X_train_ids = tokenizer.texts_to_sequences(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3467    目前 走势 良好 继续 持股 观望\n",
       "8296       伊利 行情 会 不会 一日游\n",
       "6357        现在 价位 盈利 真 不信\n",
       "3729    不要 后知后觉 尾盘 大涨 酷 酷\n",
       "9196    收市 前仓底 应该 呵呵 继续 跌\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#和原始的训练集对比一下\n",
    "#大家就明白texts_to_sequances的作用\n",
    "X_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[110, 70, 1066, 18, 102, 403],\n",
       " [1812, 48, 16, 300, 14683],\n",
       " [59, 753, 409, 106, 2925],\n",
       " [86, 9892, 51, 165, 857, 857],\n",
       " [2461, 15632, 99, 314, 18, 6]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#检查转化后的训练集\n",
    "X_train_ids[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 110, 70, 1066, 18, 102,\n",
       "        403],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1812, 48, 16, 300,\n",
       "        14683],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 59, 753, 409, 106,\n",
       "        2925],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 86, 9892, 51, 165, 857,\n",
       "        857],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2461, 15632, 99, 314,\n",
       "        18, 6]], dtype=int32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#如果要让所有样本向量化后的特征数量一致\n",
    "#就要用到填充序列的方法，pad_sequences\n",
    "#例如我们指定maxlen为64，也就是会让keras保留出现次数最多的64个词\n",
    "#作为特征\n",
    "X_train_padded = pad_sequences(X_train_ids,maxlen = 64)\n",
    "#检查一下填充后的序列\n",
    "X_train_padded[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0, 0.0, 0.0, ..., 0.0, 0.0, 0.0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#当然，我们还可以使用sequences_to_matrix来保留全部的特征\n",
    "X_train_matrix = tokenizer.sequences_to_matrix(X_train_ids, mode='binary')\n",
    "#可以检查一下转化为matrix的结果\n",
    "X_train_matrix[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15645"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#转化成matrix后的特征数量\n",
    "len(X_train_matrix[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 276, 60, 229, 2951, 38, 1,\n",
       "        786, 478],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 86, 3347, 959, 5,\n",
       "        462],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 53, 110, 10369, 670,\n",
       "        10370, 10371, 45],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 265, 121, 1176,\n",
       "        3619, 9],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 155, 229, 357, 92, 6, 470, 294, 215,\n",
       "        1917, 80, 944]], dtype=int32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#把验证集转化为序列\n",
    "X_test_ids = tokenizer.texts_to_sequences(X_test)\n",
    "#并且进行填充\n",
    "X_test_padded = pad_sequences(X_test_ids, maxlen = 64)\n",
    "#检查结果\n",
    "X_test_padded[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0, 1.0, 0.0, ..., 0.0, 0.0, 0.0])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#把验证集转化为矩阵\n",
    "X_test_matrix = tokenizer.sequences_to_matrix(X_test_ids, mode='binary')\n",
    "X_test_matrix[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 16)                250336    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 250,353\n",
      "Trainable params: 250,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#下面就可以开始模型的搭建了\n",
    "#这里我们使用Sequential模型\n",
    "model = Sequential()\n",
    "#首先向模型添加一个全连接层\n",
    "#包含16个隐藏单元，激活函数选择relu\n",
    "#input_shape选择样本特征的数量\n",
    "model.add(Dense(16, input_shape = (len(vocab)+1,), activation = 'relu'))\n",
    "#再添加一个dropout层，来降低过拟合的风险\n",
    "model.add(Dropout(0.5))\n",
    "#最后一个全连接层，激活函数为sigmoid\n",
    "#输出的结果是样本属于标签“1”的可能性\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "#几个隐藏层堆叠好，就可以对模型进行编译\n",
    "model.compile(loss = 'binary_crossentropy',\n",
    "             optimizer = 'adam',\n",
    "             metrics = ['accuracy'])\n",
    "#查看模型的概况\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6910 samples, validate on 2304 samples\n",
      "Epoch 1/10\n",
      "6910/6910 [==============================] - 2s 354us/step - loss: 0.6607 - acc: 0.6783 - val_loss: 0.6091 - val_acc: 0.8138\n",
      "Epoch 2/10\n",
      "6910/6910 [==============================] - 2s 250us/step - loss: 0.5416 - acc: 0.8386 - val_loss: 0.5058 - val_acc: 0.8702\n",
      "Epoch 3/10\n",
      "6910/6910 [==============================] - 2s 248us/step - loss: 0.4394 - acc: 0.8822 - val_loss: 0.4352 - val_acc: 0.8811\n",
      "Epoch 4/10\n",
      "6910/6910 [==============================] - 2s 250us/step - loss: 0.3649 - acc: 0.9020 - val_loss: 0.3872 - val_acc: 0.8845\n",
      "Epoch 5/10\n",
      "6910/6910 [==============================] - 2s 254us/step - loss: 0.3089 - acc: 0.9227 - val_loss: 0.3538 - val_acc: 0.8885\n",
      "Epoch 6/10\n",
      "6910/6910 [==============================] - 2s 253us/step - loss: 0.2699 - acc: 0.9318 - val_loss: 0.3314 - val_acc: 0.8911\n",
      "Epoch 7/10\n",
      "6910/6910 [==============================] - 2s 245us/step - loss: 0.2323 - acc: 0.9466 - val_loss: 0.3140 - val_acc: 0.8928\n",
      "Epoch 8/10\n",
      "6910/6910 [==============================] - 2s 253us/step - loss: 0.2087 - acc: 0.9501 - val_loss: 0.3022 - val_acc: 0.8928\n",
      "Epoch 9/10\n",
      "6910/6910 [==============================] - 2s 257us/step - loss: 0.1847 - acc: 0.9573 - val_loss: 0.2933 - val_acc: 0.8950\n",
      "Epoch 10/10\n",
      "6910/6910 [==============================] - 2s 253us/step - loss: 0.1691 - acc: 0.9603 - val_loss: 0.2869 - val_acc: 0.8958\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8958333333333334"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#下面就可以开始训练模型\n",
    "#使用128个样本组成的小批量\n",
    "#进行10个轮次的训练\n",
    "#指定转化为矩阵的验证集作为验证数据\n",
    "hist = model.fit(X_train_matrix, y_train,\n",
    "              batch_size=128,\n",
    "              epochs=10,\n",
    "              validation_data=(X_test_matrix, y_test))\n",
    "#找到模型训练过程中最高的准确率\n",
    "best_acc = max(hist.history['val_acc'])\n",
    "#检查一下最高准确率是多少\n",
    "best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2304/2304 [==============================] - 0s 107us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2868647529847092, 0.8958333333333334]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#当然，也可以使用evaluate方法对模型评估\n",
    "model.evaluate(X_test_matrix, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.6495502]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#使用模型进行预测的方法和scikit-learn也比较接近\n",
    "#我们可以随意挑一个来试试\n",
    "model.predict([X_test_matrix[:1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3596    1\n",
       "Name: polarity, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#和真值做个对比，看看模型预测是否正确\n",
    "y_test[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入几个可以让模型性能达到最优时停止训练的工具\n",
    "from keras.callbacks import Callback, EarlyStopping, ModelCheckpoint"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "MarkDown菜单",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
